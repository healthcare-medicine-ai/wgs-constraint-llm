{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428be868",
   "metadata": {
    "id": "vECLNfPmhyDb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe754b29",
   "metadata": {
    "id": "bsBOtyuTAJsC",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: scipy in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from scipy) (1.24.3)\n",
      "Requirement already satisfied: hmmlearn in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (0.3.0)\n",
      "Requirement already satisfied: numpy>=1.10 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from hmmlearn) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from hmmlearn) (1.3.0)\n",
      "Requirement already satisfied: scipy>=0.19 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from hmmlearn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (2.2.0)\n",
      "Requirement already satisfied: statsmodels in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.18 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from statsmodels) (1.24.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from statsmodels) (1.11.4)\n",
      "Requirement already satisfied: pandas>=1.0 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from statsmodels) (1.5.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from statsmodels) (23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from pandas>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from pandas>=1.0->statsmodels) (2022.7)\n",
      "Requirement already satisfied: six in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scipy\n",
    "!pip install hmmlearn\n",
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f49596f",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1703779362738,
     "user": {
      "displayName": "Oscar Thomas Aguilar",
      "userId": "15151607230073393698"
     },
     "user_tz": 300
    },
    "id": "BZfHQLuPhyDl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from hmmlearn import hmm\n",
    "import gzip\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import fisher_exact\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f46aba80",
   "metadata": {
    "executionInfo": {
     "elapsed": 173,
     "status": "ok",
     "timestamp": 1703790405518,
     "user": {
      "displayName": "Oscar Thomas Aguilar",
      "userId": "15151607230073393698"
     },
     "user_tz": 300
    },
    "id": "9IWHWPQ_hyDm"
   },
   "outputs": [],
   "source": [
    "# Specify project directories in Sherlock\n",
    "data_path = '/oak/stanford/groups/mrivas/projects/wgs-constraint-llm/data/'\n",
    "results_path = '/oak/stanford/groups/mrivas/projects/wgs-constraint-llm/osthoag/wgs-constraint-llm/results/'\n",
    "\n",
    "# Specify the file paths\n",
    "gene_annotation_file_path = data_path + 'gencode.v44.basic.annotation.gtf.gz'\n",
    "variants_file_path = data_path + 'rgc_me_variant_frequencies_20231004.vcf.gz'\n",
    "coverage_file_path = data_path + 'gnomad.exomes.v4.0.coverage.summary.tsv.bgz'\n",
    "\n",
    "rgc_predictions_file_path = results_path + 'HMM_rgc_constraint_predictions.tsv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31de63b9",
   "metadata": {
    "id": "vECLNfPmhyDb"
   },
   "source": [
    "## Define helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a5be950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the proportion of each row that overlaps with an array of positions\n",
    "def calculate_overlap(row, positions, start_col='start', end_col='end'):\n",
    "    return np.sum((row[start_col] <= positions) & (positions <= row[end_col])) / (row[end_col] - row[start_col] + 1)\n",
    "\n",
    "def get_sequence(coverage_df, variants_df):\n",
    "    # Get the length of the genetic sequence\n",
    "    sequence_length = max(coverage_df['pos'].max(), variants_df['pos'].max())\n",
    "\n",
    "    # Create boolean mask for exome coverage\n",
    "    coverage_mask = np.zeros(sequence_length + 1, dtype=bool)\n",
    "\n",
    "    # Use NumPy boolean indexing to get mask for positions with over 80% coverage\n",
    "    coverage_mask[coverage_df['pos'].to_numpy()] = 1\n",
    "\n",
    "    # Initialize values to zero for all positions\n",
    "    sequence = np.zeros(sequence_length + 1)\n",
    "\n",
    "    # Set positions to 1 where a variant exists\n",
    "    sequence[variants_df['pos'].to_numpy()] = 1\n",
    "\n",
    "    # Filter for only the protein-coding regions with over 80% exome coverage\n",
    "    observations = np.array(sequence[coverage_mask])\n",
    "    \n",
    "    positions = np.where(coverage_mask)[0]\n",
    "    \n",
    "    return observations, positions\n",
    "\n",
    "def get_HMM_predictions(observations, model, order=2):\n",
    "    # Flatten the higher-order structure\n",
    "    X = np.stack([observations[i:i-order] for i in range(order)], axis=1)\n",
    "\n",
    "    # Convert observations to counts\n",
    "    X_counts = np.column_stack([(X == i).sum(axis=1) for i in range(2)])\n",
    "\n",
    "    # Predict probabilities for each position\n",
    "    probabilities = model.predict_proba(X_counts)\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "def fit_HMM(observations, order=2):\n",
    "    # Flatten the higher-order structure\n",
    "    X = np.stack([observations[i:i-order] for i in range(order)], axis=1)\n",
    "\n",
    "    # Convert observations to counts\n",
    "    X_counts = np.column_stack([(X == i).sum(axis=1) for i in range(2)])\n",
    "\n",
    "    # Create and fit a first-order HMM\n",
    "    model = hmm.MultinomialHMM(n_components=2, random_state=10)\n",
    "    model.fit(X_counts)\n",
    "\n",
    "    return model\n",
    "\n",
    "def fit_and_predict_HMM(observations, order=2):\n",
    "    # Flatten the higher-order structure\n",
    "    X = np.stack([observations[i:i-order] for i in range(order)], axis=1)\n",
    "\n",
    "    # Convert observations to counts\n",
    "    X_counts = np.column_stack([(X == i).sum(axis=1) for i in range(2)])\n",
    "\n",
    "    # Create and fit a first-order HMM\n",
    "    model = hmm.MultinomialHMM(n_components=2, random_state=10)\n",
    "    model.fit(X_counts)\n",
    "\n",
    "    # Predict probabilities for each position\n",
    "    probabilities = model.predict_proba(X_counts)\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "def ols_regression(predictions_df):\n",
    "    # Add a constant term to the independent variable for the intercept\n",
    "    X = sm.add_constant(predictions_df['prob_0'])\n",
    "\n",
    "    # Fit the linear regression model\n",
    "    model4 = sm.OLS(predictions_df['observation'],X).fit()\n",
    "\n",
    "    model4.summary().tables[1].pvalues_precision = 100  # Adjust the number of significant digits\n",
    "\n",
    "    # Get the summary of the regression\n",
    "    print(model4.summary())\n",
    "\n",
    "    # Extract the F-statistic and its associated p-value\n",
    "    f_statistic = model4.fvalue\n",
    "    p_value_f_statistic = model4.f_pvalue\n",
    "    \n",
    "    return f_statistic, p_value_f_statistic\n",
    "\n",
    "def fishers_exact_test(gene_id, ac_case, an_case, ac_ctrl, an_ctrl):\n",
    "    if any((value < 0) or (math.isnan(value)) for value in [ac_case, an_case - ac_case, ac_ctrl, an_ctrl - ac_ctrl]):\n",
    "        print(f\"Negative values detected: gene={gene_id}, ac_case={ac_case}, an_case={an_case}, ac_ctrl={ac_ctrl}, an_ctrl={an_ctrl}\")\n",
    "        return None, None\n",
    "\n",
    "    contingency_table = [[ac_case, an_case - ac_case], [ac_ctrl, an_ctrl - ac_ctrl]]\n",
    "    odds_ratio, p_value = fisher_exact(contingency_table)\n",
    "    return odds_ratio, p_value\n",
    "\n",
    "def apply_fishers_exact_test(cases_df):\n",
    "    # Apply only to the pLoFs\n",
    "    cases_df = cases_df[cases_df['consequence'] == 'pLoF']\n",
    "    \n",
    "    # Calculate total counts for cases and controls\n",
    "    cases_df['total_ac_case'] = cases_df.groupby(['gene_id', 'group'])['ac_case'].transform('sum')\n",
    "    cases_df['total_an_case'] = cases_df.groupby(['gene_id', 'group'])['an_case'].transform('max')\n",
    "    cases_df['total_ac_ctrl'] = cases_df.groupby(['gene_id', 'group'])['ac_ctrl'].transform('sum')\n",
    "    cases_df['total_an_ctrl'] = cases_df.groupby(['gene_id', 'group'])['an_ctrl'].transform('max')\n",
    "\n",
    "    # Remove duplicate rows for unique combinations of 'gene_id' and 'group'\n",
    "    unique_cases_df = cases_df[['gene_id', 'gene_name', 'group', 'total_ac_case', 'total_an_case', 'total_ac_ctrl', 'total_an_ctrl']].drop_duplicates()\n",
    "\n",
    "    # Drop Nan values from gene_id\n",
    "    unique_cases_df = unique_cases_df.dropna(subset=['gene_id'])\n",
    "\n",
    "    # Apply Fisher's exact test for each unique combination\n",
    "    unique_cases_df[['odds_ratio', 'p_value']] = unique_cases_df.apply(lambda row: fishers_exact_test(row['gene_id'],row['total_ac_case'], row['total_an_case'], row['total_ac_ctrl'], row['total_an_ctrl']), axis=1, result_type='expand')\n",
    "\n",
    "    # Sort the DataFrame by 'p_value' in increasing order\n",
    "    sorted_df = unique_cases_df.sort_values(by='p_value')\n",
    "    \n",
    "    return sorted_df\n",
    "    \n",
    "from scipy.stats import chi2\n",
    "def fisher_method_p_value(p_values):\n",
    "    \"\"\"\n",
    "    Combine p-values using Fisher's method.\n",
    "\n",
    "    Parameters:\n",
    "    - p_values: List of p-values to be combined.\n",
    "\n",
    "    Returns:\n",
    "    - Combined p-value.\n",
    "    \"\"\"\n",
    "    if len(p_values) < 2:\n",
    "        raise ValueError(\"At least two p-values are required for Fisher's method.\")\n",
    "        \n",
    "    # Drop NaN values\n",
    "    p_values = p_values[~np.isnan(p_values)]\n",
    "\n",
    "    # Convert p-values to chi-squared statistics\n",
    "    chi_squared_stats = -2 * np.log(p_values)\n",
    "\n",
    "    # Sum of chi-squared statistics\n",
    "    chi_squared_sum = np.sum(chi_squared_stats)\n",
    "\n",
    "    # Degrees of freedom for the chi-squared distribution\n",
    "    degrees_of_freedom = 2 * len(p_values)\n",
    "\n",
    "    # Combined p-value using chi-squared distribution\n",
    "    combined_p_value = 1 - chi2.cdf(chi_squared_sum, degrees_of_freedom)\n",
    "\n",
    "    return combined_p_value\n",
    "\n",
    "def plot_hist_from_predictions(predictions_df):\n",
    "    # Create a figure with two subplots in one row and two columns\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Plot the first histogram in the first subplot\n",
    "    axs[0].hist(predictions_df['observation'], edgecolor=\"blue\")\n",
    "    axs[0].set_title('Histogram of Observations')\n",
    "    axs[0].set_xlabel('Has a variant')\n",
    "    axs[0].set_ylabel('Frequency')\n",
    "\n",
    "    # Plot the second histogram in the second subplot\n",
    "    axs[1].hist(predictions_df['prob_0'], edgecolor=\"blue\")\n",
    "    axs[1].set_title('Histogram of Predictions')\n",
    "    axs[1].set_xlabel('Probability of 0')\n",
    "    axs[1].set_ylabel('Frequency')\n",
    "\n",
    "    # Adjust layout to prevent clipping of titles\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plots\n",
    "    plt.show()\n",
    "    \n",
    "def plot_subsequence_predictions(start_idx, end_idx, name='Target Region'):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 5), sharex=True)\n",
    "    plt.suptitle(\"Actual vs Predicted for \" + name)\n",
    "\n",
    "    # Plot the original sequence\n",
    "    axes[0].bar(range(start_idx, end_idx), observations[start_idx:end_idx], color='blue', label='Original Sequence')\n",
    "    axes[0].set_ylabel('Observation')\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Plot the predicted probabilities as stacked barplots\n",
    "    axes[1].bar(range(start_idx, end_idx), probabilities[start_idx:end_idx, 0], color='orange', label='Probability of 0')\n",
    "    axes[1].bar(range(start_idx, end_idx), probabilities[start_idx:end_idx, 1], bottom=probabilities[start_idx:end_idx, 0], color='green', label='Probability of 1')\n",
    "    axes[1].set_xlabel('Position')\n",
    "    axes[1].set_ylabel('Prediction')\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02748d2a",
   "metadata": {
    "id": "yAEgmgmSGY7d"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba74ed58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 87986,
     "status": "ok",
     "timestamp": 1703321915656,
     "user": {
      "displayName": "Oscar Thomas Aguilar",
      "userId": "15151607230073393698"
     },
     "user_tz": 300
    },
    "id": "Bz601YCxD8vb",
    "outputId": "8d636ae6-142b-4681-ca77-89e68e1cc0d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>over_10</th>\n",
       "      <th>over_20</th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>chr1</td>\n",
       "      <td>11819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>chr1</td>\n",
       "      <td>11820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>chr1</td>\n",
       "      <td>11821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>chr1</td>\n",
       "      <td>11822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>chr1</td>\n",
       "      <td>11823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170202922</th>\n",
       "      <td>0.29592</td>\n",
       "      <td>0.23756</td>\n",
       "      <td>chrM</td>\n",
       "      <td>16069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170202923</th>\n",
       "      <td>0.29582</td>\n",
       "      <td>0.23788</td>\n",
       "      <td>chrM</td>\n",
       "      <td>16070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170202924</th>\n",
       "      <td>0.29689</td>\n",
       "      <td>0.23808</td>\n",
       "      <td>chrM</td>\n",
       "      <td>16071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170202925</th>\n",
       "      <td>0.29674</td>\n",
       "      <td>0.23815</td>\n",
       "      <td>chrM</td>\n",
       "      <td>16072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170202926</th>\n",
       "      <td>0.29712</td>\n",
       "      <td>0.23825</td>\n",
       "      <td>chrM</td>\n",
       "      <td>16073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170202927 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           over_10  over_20   chr    pos\n",
       "0          0.00000  0.00000  chr1  11819\n",
       "1          0.00000  0.00000  chr1  11820\n",
       "2          0.00000  0.00000  chr1  11821\n",
       "3          0.00000  0.00000  chr1  11822\n",
       "4          0.00000  0.00000  chr1  11823\n",
       "...            ...      ...   ...    ...\n",
       "170202922  0.29592  0.23756  chrM  16069\n",
       "170202923  0.29582  0.23788  chrM  16070\n",
       "170202924  0.29689  0.23808  chrM  16071\n",
       "170202925  0.29674  0.23815  chrM  16072\n",
       "170202926  0.29712  0.23825  chrM  16073\n",
       "\n",
       "[170202927 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open(coverage_file_path, 'rt') as coverage_file:\n",
    "    # Read the file into a pandas DataFrame\n",
    "    coverage_df = pd.read_csv(coverage_file, sep='\\t',\n",
    "                             usecols=['locus', 'over_10', 'over_20'])\n",
    "\n",
    "# Expand locus column\n",
    "coverage_df[['chr', 'pos']] = coverage_df['locus'].str.split(':', expand=True)\n",
    "coverage_df['pos'] = coverage_df['pos'].astype(int)\n",
    "\n",
    "# Drop the original locus column\n",
    "coverage_df = coverage_df.drop('locus', axis=1)\n",
    "\n",
    "coverage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e140df9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 54171,
     "status": "ok",
     "timestamp": 1703323440602,
     "user": {
      "displayName": "Oscar Thomas Aguilar",
      "userId": "15151607230073393698"
     },
     "user_tz": 300
    },
    "id": "-kMYvaQmGs44",
    "outputId": "70fd4749-819f-42a6-98c3-c7e4c6f6d22a",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>source</th>\n",
       "      <th>feature</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>score</th>\n",
       "      <th>strand</th>\n",
       "      <th>frame</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>gene_type</th>\n",
       "      <th>gene_name</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>transcript</th>\n",
       "      <th>transcript_num</th>\n",
       "      <th>transcript_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>chr1</td>\n",
       "      <td>HAVANA</td>\n",
       "      <td>CDS</td>\n",
       "      <td>65565</td>\n",
       "      <td>65573</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000186092.7</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>ENST00000641515.2</td>\n",
       "      <td>ENST00000641515</td>\n",
       "      <td>2</td>\n",
       "      <td>OR4F5-201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>chr1</td>\n",
       "      <td>HAVANA</td>\n",
       "      <td>CDS</td>\n",
       "      <td>69037</td>\n",
       "      <td>70005</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000186092.7</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>ENST00000641515.2</td>\n",
       "      <td>ENST00000641515</td>\n",
       "      <td>2</td>\n",
       "      <td>OR4F5-201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>chr1</td>\n",
       "      <td>HAVANA</td>\n",
       "      <td>CDS</td>\n",
       "      <td>450743</td>\n",
       "      <td>451678</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000284733.2</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>OR4F29</td>\n",
       "      <td>ENST00000426406.4</td>\n",
       "      <td>ENST00000426406</td>\n",
       "      <td>4</td>\n",
       "      <td>OR4F29-201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>chr1</td>\n",
       "      <td>HAVANA</td>\n",
       "      <td>CDS</td>\n",
       "      <td>685719</td>\n",
       "      <td>686654</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000284662.2</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>OR4F16</td>\n",
       "      <td>ENST00000332831.5</td>\n",
       "      <td>ENST00000332831</td>\n",
       "      <td>5</td>\n",
       "      <td>OR4F16-201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>chr1</td>\n",
       "      <td>HAVANA</td>\n",
       "      <td>CDS</td>\n",
       "      <td>924432</td>\n",
       "      <td>924948</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000187634.13</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>SAMD11</td>\n",
       "      <td>ENST00000616016.5</td>\n",
       "      <td>ENST00000616016</td>\n",
       "      <td>5</td>\n",
       "      <td>SAMD11-209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998488</th>\n",
       "      <td>chrM</td>\n",
       "      <td>ENSEMBL</td>\n",
       "      <td>CDS</td>\n",
       "      <td>10470</td>\n",
       "      <td>10763</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000212907.2</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>MT-ND4L</td>\n",
       "      <td>ENST00000361335.1</td>\n",
       "      <td>ENST00000361335</td>\n",
       "      <td>1</td>\n",
       "      <td>MT-ND4L-201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998495</th>\n",
       "      <td>chrM</td>\n",
       "      <td>ENSEMBL</td>\n",
       "      <td>CDS</td>\n",
       "      <td>10760</td>\n",
       "      <td>12137</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000198886.2</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>MT-ND4</td>\n",
       "      <td>ENST00000361381.2</td>\n",
       "      <td>ENST00000361381</td>\n",
       "      <td>2</td>\n",
       "      <td>MT-ND4-201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998509</th>\n",
       "      <td>chrM</td>\n",
       "      <td>ENSEMBL</td>\n",
       "      <td>CDS</td>\n",
       "      <td>12337</td>\n",
       "      <td>14145</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000198786.2</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>MT-ND5</td>\n",
       "      <td>ENST00000361567.2</td>\n",
       "      <td>ENST00000361567</td>\n",
       "      <td>2</td>\n",
       "      <td>MT-ND5-201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998515</th>\n",
       "      <td>chrM</td>\n",
       "      <td>ENSEMBL</td>\n",
       "      <td>CDS</td>\n",
       "      <td>14149</td>\n",
       "      <td>14673</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000198695.2</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>MT-ND6</td>\n",
       "      <td>ENST00000361681.2</td>\n",
       "      <td>ENST00000361681</td>\n",
       "      <td>2</td>\n",
       "      <td>MT-ND6-201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998523</th>\n",
       "      <td>chrM</td>\n",
       "      <td>ENSEMBL</td>\n",
       "      <td>CDS</td>\n",
       "      <td>14747</td>\n",
       "      <td>15887</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000198727.2</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>MT-CYB</td>\n",
       "      <td>ENST00000361789.2</td>\n",
       "      <td>ENST00000361789</td>\n",
       "      <td>2</td>\n",
       "      <td>MT-CYB-201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>654548 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          chr   source feature   start     end score strand frame  \\\n",
       "60       chr1   HAVANA     CDS   65565   65573     .      +     0   \n",
       "63       chr1   HAVANA     CDS   69037   70005     .      +     0   \n",
       "236      chr1   HAVANA     CDS  450743  451678     .      -     0   \n",
       "304      chr1   HAVANA     CDS  685719  686654     .      -     0   \n",
       "524      chr1   HAVANA     CDS  924432  924948     .      +     0   \n",
       "...       ...      ...     ...     ...     ...   ...    ...   ...   \n",
       "1998488  chrM  ENSEMBL     CDS   10470   10763     .      +     0   \n",
       "1998495  chrM  ENSEMBL     CDS   10760   12137     .      +     0   \n",
       "1998509  chrM  ENSEMBL     CDS   12337   14145     .      +     0   \n",
       "1998515  chrM  ENSEMBL     CDS   14149   14673     .      -     0   \n",
       "1998523  chrM  ENSEMBL     CDS   14747   15887     .      +     0   \n",
       "\n",
       "                    gene_id       gene_type gene_name      transcript_id  \\\n",
       "60        ENSG00000186092.7  protein_coding     OR4F5  ENST00000641515.2   \n",
       "63        ENSG00000186092.7  protein_coding     OR4F5  ENST00000641515.2   \n",
       "236       ENSG00000284733.2  protein_coding    OR4F29  ENST00000426406.4   \n",
       "304       ENSG00000284662.2  protein_coding    OR4F16  ENST00000332831.5   \n",
       "524      ENSG00000187634.13  protein_coding    SAMD11  ENST00000616016.5   \n",
       "...                     ...             ...       ...                ...   \n",
       "1998488   ENSG00000212907.2  protein_coding   MT-ND4L  ENST00000361335.1   \n",
       "1998495   ENSG00000198886.2  protein_coding    MT-ND4  ENST00000361381.2   \n",
       "1998509   ENSG00000198786.2  protein_coding    MT-ND5  ENST00000361567.2   \n",
       "1998515   ENSG00000198695.2  protein_coding    MT-ND6  ENST00000361681.2   \n",
       "1998523   ENSG00000198727.2  protein_coding    MT-CYB  ENST00000361789.2   \n",
       "\n",
       "              transcript transcript_num transcript_name  \n",
       "60       ENST00000641515              2       OR4F5-201  \n",
       "63       ENST00000641515              2       OR4F5-201  \n",
       "236      ENST00000426406              4      OR4F29-201  \n",
       "304      ENST00000332831              5      OR4F16-201  \n",
       "524      ENST00000616016              5      SAMD11-209  \n",
       "...                  ...            ...             ...  \n",
       "1998488  ENST00000361335              1     MT-ND4L-201  \n",
       "1998495  ENST00000361381              2      MT-ND4-201  \n",
       "1998509  ENST00000361567              2      MT-ND5-201  \n",
       "1998515  ENST00000361681              2      MT-ND6-201  \n",
       "1998523  ENST00000361789              2      MT-CYB-201  \n",
       "\n",
       "[654548 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the GTF file into a pandas DataFrame\n",
    "gene_df = pd.read_csv(gene_annotation_file_path, sep='\\t', comment='#', header=None, \n",
    "                      names=['chr', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attribute'], \n",
    "                      dtype={'start': int, 'end': int})\n",
    "\n",
    "# Extract 'gene_id' from attributes\n",
    "gene_df['gene_id'] = gene_df['attribute'].str.extract(r'gene_id \"(.*?)\"')\n",
    "\n",
    "# Extract 'gene_type' from attributes\n",
    "gene_df['gene_type'] = gene_df['attribute'].str.extract(r'gene_type \"(.*?)\"')\n",
    "\n",
    "# Extract 'gene_name' from attributes\n",
    "gene_df['gene_name'] = gene_df['attribute'].str.extract(r'gene_name \"(.*?)\"')\n",
    "\n",
    "# Extract 'transcript_id' from attributes\n",
    "gene_df['transcript_id'] = gene_df['attribute'].str.extract(r'transcript_id \"(.*?)\"')\n",
    "\n",
    "# Extract 'transcript' and 'num' from transcript_id\n",
    "gene_df[['transcript', 'transcript_num']] = gene_df['transcript_id'].str.split('.', expand=True)\n",
    "\n",
    "# Extract 'transcript_name' from attributes\n",
    "gene_df['transcript_name'] = gene_df['attribute'].str.extract(r'transcript_name \"(.*?)\"')\n",
    "\n",
    "# Drop the original attribute column\n",
    "gene_df = gene_df.drop('attribute', axis=1)\n",
    "\n",
    "# Filter rows for protein-coding regions\n",
    "gene_df = gene_df[(gene_df['gene_type'] == 'protein_coding') & (gene_df['feature'] == 'CDS')]\n",
    "\n",
    "gene_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9263f924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dataframe to store the concatenated data\n",
    "variants_df = pd.DataFrame()\n",
    "\n",
    "# Check if the joined file already exists\n",
    "if not os.path.exists(variants_file_path):\n",
    "    # Loop through chromosomes and append dataframes with tqdm\n",
    "    for chromnum in tqdm(range(1, 23), desc='Processing Chromosomes'):\n",
    "        # Read the variants file into a pandas DataFrame\n",
    "        chr_variants_df = pd.read_csv(\n",
    "            \"rgc_me_variant_frequencies_chr\" + str(chromnum) + \"_20231004.vcf.gz\",\n",
    "            comment='#',\n",
    "            sep='\\t',\n",
    "            header=None,\n",
    "            names=['chr', 'pos', 'variant', 'ref', 'alt', 'quality', 'filter', 'info'],\n",
    "            dtype={'pos': int},\n",
    "            usecols=[i for i in range(8)]\n",
    "        )\n",
    "\n",
    "        # Append the dataframe to the main dataframe\n",
    "        variants_df = pd.concat([variants_df, chr_variants_df], ignore_index=True)\n",
    "\n",
    "    # Write gene_domain_df to a csv to avoid recomputing\n",
    "    variants_df.to_csv(variants_file_path, index=False, compression='gzip', sep='\\t')\n",
    "    \n",
    "else:\n",
    "    # Read the file into a pandas DataFrame\n",
    "    variants_df = pd.read_csv(variants_file_path, sep='\\t')\n",
    "\n",
    "variants_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6795a79b",
   "metadata": {},
   "source": [
    "## Train HMM on RGC chromosome 2 and get predictions for all exomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95d5810",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_thr = 0.5\n",
    "coverage_category = 'over_10'\n",
    "print(str(coverage_thr)+'_'+coverage_category.replace('_',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74916d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for analysis\n",
    "order = 2\n",
    "coverage_thr = 0.9\n",
    "coverage_category = 'over_20'\n",
    "\n",
    "# Define coverage filter\n",
    "# coverage_filter = '0.5_over10' # coverage['over_10'] > 0.5\n",
    "coverage_filter = '0.9_over20' # coverage['over_20'] > 0.9\n",
    "\n",
    "# Define model name (and absolute path)\n",
    "model_name = results_path + 'HMM_rgc_' + coverage_filter + '_chr2'\n",
    "\n",
    "# Initialize empty dataframes\n",
    "predictions_df = pd.DataFrame(columns=['chr', 'pos','prob_0', 'prob_1', 'observation'])\n",
    "\n",
    "# Filter rows for chromosome 2\n",
    "chr_gene_df = gene_df[gene_df['chr'] == 'chr2']\n",
    "chr_variants_df = variants_df[variants_df['chr'] == 2]\n",
    "chr_coverage_df = coverage_df[(coverage_df['chr'] == 'chr2') & (coverage_df[coverage_category] > coverage_thr)]\n",
    "\n",
    "# Get training data for the chromosome\n",
    "observations, positions = get_sequence(chr_gene_df, chr_coverage_df, chr_variants_df)\n",
    "\n",
    "# Fit HMM to Chromosome 2\n",
    "model = fit_HMM(observations, order=order)\n",
    "\n",
    "for chromnum in range(1,23):\n",
    "    print('-'*100)\n",
    "    print(\"PROCESSING CHROMOSOME\", str(chromnum))\n",
    "\n",
    "    # Filter rows for given chromosome\n",
    "    chr_gene_df = gene_df[gene_df['chr'] == 'chr' + str(chromnum)]\n",
    "    chr_variants_df = variants_df[variants_df['chr'] == chromnum]\n",
    "    chr_coverage_df = coverage_df[(coverage_df['chr'] == 'chr' + str(chromnum)) & (coverage_df[coverage_category] > coverage_thr)]\n",
    "    \n",
    "    # Get training data for the chromosome\n",
    "    observations, positions = get_sequence(chr_gene_df, chr_coverage_df, chr_variants_df)\n",
    "\n",
    "    # Fit HMM and retrieve probabilites\n",
    "    probabilities = get_HMM_predictions(observations, model, order=order)\n",
    "    \n",
    "    # Create a DataFrame with 'pos' reflecting the index of the original sequence and 'prob_0/1' as the predictions\n",
    "    chr_predictions_df = pd.DataFrame({'chr': 'chr' + str(chromnum),\n",
    "                                       'pos': positions[0:-order],\n",
    "                                       'prob_0': probabilities[:, 0], \n",
    "                                       'prob_1': probabilities[:, 1], \n",
    "                                       'observation': observations[0:-order]\n",
    "                                      })\n",
    "    \n",
    "    # Plot histograms for predicted vs observed variants\n",
    "    plot_hist_from_predictions(chr_predictions_df)\n",
    "    \n",
    "    # Append predictions to overall df\n",
    "    predictions_df = pd.concat([predictions_df, chr_predictions_df], ignore_index=True)\n",
    "    \n",
    "    # Run regression\n",
    "    f_statistic, p_value_f_statistic = ols_regression(chr_predictions_df)\n",
    "\n",
    "# Write predictions_df to a csv to avoid recomputing\n",
    "predictions_df.to_csv(model_name + \"_predictions_rgc_wgs.tsv.gz\", index=False, compression='gzip', sep='\\t')\n",
    "\n",
    "predictions_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
