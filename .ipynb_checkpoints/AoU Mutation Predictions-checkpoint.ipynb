{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7610e27",
   "metadata": {
    "id": "vECLNfPmhyDb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9599826",
   "metadata": {
    "id": "bsBOtyuTAJsC",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: scipy in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from scipy) (1.24.3)\n",
      "Requirement already satisfied: hmmlearn in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (0.3.0)\n",
      "Requirement already satisfied: numpy>=1.10 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from hmmlearn) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from hmmlearn) (1.3.0)\n",
      "Requirement already satisfied: scipy>=0.19 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from hmmlearn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (2.2.0)\n",
      "Requirement already satisfied: statsmodels in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.18 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from statsmodels) (1.24.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from statsmodels) (1.11.4)\n",
      "Requirement already satisfied: pandas>=1.0 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from statsmodels) (1.5.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from statsmodels) (23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from pandas>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from pandas>=1.0->statsmodels) (2022.7)\n",
      "Requirement already satisfied: six in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Requirement already satisfied: mpl_scatter_density in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (0.7)\n",
      "Requirement already satisfied: numpy in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from mpl_scatter_density) (1.24.3)\n",
      "Requirement already satisfied: matplotlib>=3.0 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from mpl_scatter_density) (3.7.1)\n",
      "Requirement already satisfied: fast-histogram>=0.3 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from mpl_scatter_density) (0.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0->mpl_scatter_density) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0->mpl_scatter_density) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0->mpl_scatter_density) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0->mpl_scatter_density) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0->mpl_scatter_density) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0->mpl_scatter_density) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0->mpl_scatter_density) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0->mpl_scatter_density) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.0->mpl_scatter_density) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (4.65.0)\n",
      "Requirement already satisfied: colorama in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (0.4.6)\n",
      "Requirement already satisfied: pyliftover in /oak/stanford/groups/mrivas/users/osthoag/anaconda3/lib/python3.11/site-packages (0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scipy\n",
    "!pip install hmmlearn\n",
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f00b492",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1703779362738,
     "user": {
      "displayName": "Oscar Thomas Aguilar",
      "userId": "15151607230073393698"
     },
     "user_tz": 300
    },
    "id": "BZfHQLuPhyDl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from hmmlearn import hmm\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import fisher_exact\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feae3e50",
   "metadata": {
    "executionInfo": {
     "elapsed": 173,
     "status": "ok",
     "timestamp": 1703790405518,
     "user": {
      "displayName": "Oscar Thomas Aguilar",
      "userId": "15151607230073393698"
     },
     "user_tz": 300
    },
    "id": "9IWHWPQ_hyDm"
   },
   "outputs": [],
   "source": [
    "# Specify project directories in Sherlock\n",
    "data_path = '/oak/stanford/groups/mrivas/projects/wgs-constraint-llm/data/'\n",
    "results_path = '/oak/stanford/groups/mrivas/projects/wgs-constraint-llm/osthoag/wgs-constraint-llm/results/'\n",
    "\n",
    "# Specify the file paths\n",
    "aou_variants_file_path = data_path + 'aou_variants.tsv.gz'\n",
    "genome_coverage_file_path = data_path + 'gnomad.genomes.r3.0.1.coverage.summary.tsv.bgz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a232aea",
   "metadata": {
    "id": "vECLNfPmhyDb"
   },
   "source": [
    "## Define helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b70a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the proportion of each row that overlaps with an array of positions\n",
    "def calculate_overlap(row, positions, start_col='start', end_col='end'):\n",
    "    return np.sum((row[start_col] <= positions) & (positions <= row[end_col])) / (row[end_col] - row[start_col] + 1)\n",
    "\n",
    "def get_sequence(coverage_df, variants_df):\n",
    "    # Get the length of the genetic sequence\n",
    "    sequence_length = max(coverage_df['pos'].max(), variants_df['pos'].max())\n",
    "\n",
    "    # Create boolean mask for exome coverage\n",
    "    coverage_mask = np.zeros(sequence_length + 1, dtype=bool)\n",
    "\n",
    "    # Use NumPy boolean indexing to get mask for positions with over 80% coverage\n",
    "    coverage_mask[coverage_df['pos'].to_numpy()] = 1\n",
    "\n",
    "    # Initialize values to zero for all positions\n",
    "    sequence = np.zeros(sequence_length + 1)\n",
    "\n",
    "    # Set positions to 1 where a variant exists\n",
    "    sequence[variants_df['pos'].to_numpy()] = 1\n",
    "\n",
    "    # Filter for only the protein-coding regions with over 80% exome coverage\n",
    "    observations = np.array(sequence[coverage_mask])\n",
    "    \n",
    "    positions = np.where(coverage_mask)[0]\n",
    "    \n",
    "    return observations, positions\n",
    "\n",
    "def get_HMM_predictions(observations, model, order=2):\n",
    "    # Flatten the higher-order structure\n",
    "    X = np.stack([observations[i:i-order] for i in range(order)], axis=1)\n",
    "\n",
    "    # Convert observations to counts\n",
    "    X_counts = np.column_stack([(X == i).sum(axis=1) for i in range(2)])\n",
    "\n",
    "    # Predict probabilities for each position\n",
    "    probabilities = model.predict_proba(X_counts)\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "def fit_HMM(observations, order=2):\n",
    "    # Flatten the higher-order structure\n",
    "    X = np.stack([observations[i:i-order] for i in range(order)], axis=1)\n",
    "\n",
    "    # Convert observations to counts\n",
    "    X_counts = np.column_stack([(X == i).sum(axis=1) for i in range(2)])\n",
    "\n",
    "    # Create and fit a first-order HMM\n",
    "    model = hmm.MultinomialHMM(n_components=2, random_state=10)\n",
    "    model.fit(X_counts)\n",
    "\n",
    "    return model\n",
    "\n",
    "def fit_and_predict_HMM(observations, order=2):\n",
    "    # Flatten the higher-order structure\n",
    "    X = np.stack([observations[i:i-order] for i in range(order)], axis=1)\n",
    "\n",
    "    # Convert observations to counts\n",
    "    X_counts = np.column_stack([(X == i).sum(axis=1) for i in range(2)])\n",
    "\n",
    "    # Create and fit a first-order HMM\n",
    "    model = hmm.MultinomialHMM(n_components=2, random_state=10)\n",
    "    model.fit(X_counts)\n",
    "\n",
    "    # Predict probabilities for each position\n",
    "    probabilities = model.predict_proba(X_counts)\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "def ols_regression(predictions_df):\n",
    "    # Add a constant term to the independent variable for the intercept\n",
    "    X = sm.add_constant(predictions_df['prob_0'])\n",
    "\n",
    "    # Fit the linear regression model\n",
    "    model4 = sm.OLS(predictions_df['observation'],X).fit()\n",
    "\n",
    "    model4.summary().tables[1].pvalues_precision = 100  # Adjust the number of significant digits\n",
    "\n",
    "    # Get the summary of the regression\n",
    "    print(model4.summary())\n",
    "\n",
    "    # Extract the F-statistic and its associated p-value\n",
    "    f_statistic = model4.fvalue\n",
    "    p_value_f_statistic = model4.f_pvalue\n",
    "    \n",
    "    return f_statistic, p_value_f_statistic\n",
    "\n",
    "def fishers_exact_test(gene_id, ac_case, an_case, ac_ctrl, an_ctrl):\n",
    "    if any((value < 0) or (math.isnan(value)) for value in [ac_case, an_case - ac_case, ac_ctrl, an_ctrl - ac_ctrl]):\n",
    "        print(f\"Negative values detected: gene={gene_id}, ac_case={ac_case}, an_case={an_case}, ac_ctrl={ac_ctrl}, an_ctrl={an_ctrl}\")\n",
    "        return None, None\n",
    "\n",
    "    contingency_table = [[ac_case, an_case - ac_case], [ac_ctrl, an_ctrl - ac_ctrl]]\n",
    "    odds_ratio, p_value = fisher_exact(contingency_table)\n",
    "    return odds_ratio, p_value\n",
    "\n",
    "def apply_fishers_exact_test(cases_df):\n",
    "    # Apply only to the pLoFs\n",
    "    cases_df = cases_df[cases_df['consequence'] == 'pLoF']\n",
    "    \n",
    "    # Calculate total counts for cases and controls\n",
    "    cases_df['total_ac_case'] = cases_df.groupby(['gene_id', 'group'])['ac_case'].transform('sum')\n",
    "    cases_df['total_an_case'] = cases_df.groupby(['gene_id', 'group'])['an_case'].transform('max')\n",
    "    cases_df['total_ac_ctrl'] = cases_df.groupby(['gene_id', 'group'])['ac_ctrl'].transform('sum')\n",
    "    cases_df['total_an_ctrl'] = cases_df.groupby(['gene_id', 'group'])['an_ctrl'].transform('max')\n",
    "\n",
    "    # Remove duplicate rows for unique combinations of 'gene_id' and 'group'\n",
    "    unique_cases_df = cases_df[['gene_id', 'gene_name', 'group', 'total_ac_case', 'total_an_case', 'total_ac_ctrl', 'total_an_ctrl']].drop_duplicates()\n",
    "\n",
    "    # Drop Nan values from gene_id\n",
    "    unique_cases_df = unique_cases_df.dropna(subset=['gene_id'])\n",
    "\n",
    "    # Apply Fisher's exact test for each unique combination\n",
    "    unique_cases_df[['odds_ratio', 'p_value']] = unique_cases_df.apply(lambda row: fishers_exact_test(row['gene_id'],row['total_ac_case'], row['total_an_case'], row['total_ac_ctrl'], row['total_an_ctrl']), axis=1, result_type='expand')\n",
    "\n",
    "    # Sort the DataFrame by 'p_value' in increasing order\n",
    "    sorted_df = unique_cases_df.sort_values(by='p_value')\n",
    "    \n",
    "    return sorted_df\n",
    "\n",
    "# Initialize the liftover object for hg19 to hg38\n",
    "lo = LiftOver('hg19', 'hg38')\n",
    "\n",
    "# Function to liftover a single row\n",
    "def liftover(row):\n",
    "    lifted = lo.convert_coordinate(row['chr'], row['pos'])\n",
    "    if lifted:\n",
    "        # Returns the first lifted coordinate (chromosome, position)\n",
    "        return lifted[0][0], int(lifted[0][1])\n",
    "    else:\n",
    "        # Returns 0 if liftover fails\n",
    "        return row['chr'], 0\n",
    "    \n",
    "from scipy.stats import chi2\n",
    "def fisher_method_p_value(p_values):\n",
    "    \"\"\"\n",
    "    Combine p-values using Fisher's method.\n",
    "\n",
    "    Parameters:\n",
    "    - p_values: List of p-values to be combined.\n",
    "\n",
    "    Returns:\n",
    "    - Combined p-value.\n",
    "    \"\"\"\n",
    "    if len(p_values) < 2:\n",
    "        raise ValueError(\"At least two p-values are required for Fisher's method.\")\n",
    "        \n",
    "    # Drop NaN values\n",
    "    p_values = p_values[~np.isnan(p_values)]\n",
    "\n",
    "    # Convert p-values to chi-squared statistics\n",
    "    chi_squared_stats = -2 * np.log(p_values)\n",
    "\n",
    "    # Sum of chi-squared statistics\n",
    "    chi_squared_sum = np.sum(chi_squared_stats)\n",
    "\n",
    "    # Degrees of freedom for the chi-squared distribution\n",
    "    degrees_of_freedom = 2 * len(p_values)\n",
    "\n",
    "    # Combined p-value using chi-squared distribution\n",
    "    combined_p_value = 1 - chi2.cdf(chi_squared_sum, degrees_of_freedom)\n",
    "\n",
    "    return combined_p_value\n",
    "\n",
    "def plot_hist_from_predictions(predictions_df):\n",
    "    # Create a figure with two subplots in one row and two columns\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Plot the first histogram in the first subplot\n",
    "    axs[0].hist(predictions_df['observation'], edgecolor=\"blue\")\n",
    "    axs[0].set_title('Histogram of Observations')\n",
    "    axs[0].set_xlabel('Has a variant')\n",
    "    axs[0].set_ylabel('Frequency')\n",
    "\n",
    "    # Plot the second histogram in the second subplot\n",
    "    axs[1].hist(predictions_df['prob_0'], edgecolor=\"blue\")\n",
    "    axs[1].set_title('Histogram of Predictions')\n",
    "    axs[1].set_xlabel('Probability of 0')\n",
    "    axs[1].set_ylabel('Frequency')\n",
    "\n",
    "    # Adjust layout to prevent clipping of titles\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plots\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e9090",
   "metadata": {
    "id": "yAEgmgmSGY7d"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4c787f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>10073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>10108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>10110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>10113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934655699</th>\n",
       "      <td>chrY</td>\n",
       "      <td>56887741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934655700</th>\n",
       "      <td>chrY</td>\n",
       "      <td>56887744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934655701</th>\n",
       "      <td>chrY</td>\n",
       "      <td>56887793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934655702</th>\n",
       "      <td>chrY</td>\n",
       "      <td>56887802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934655703</th>\n",
       "      <td>chrY</td>\n",
       "      <td>56887898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>934655704 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            chr       pos\n",
       "0          chr1     10001\n",
       "1          chr1     10073\n",
       "2          chr1     10108\n",
       "3          chr1     10110\n",
       "4          chr1     10113\n",
       "...         ...       ...\n",
       "934655699  chrY  56887741\n",
       "934655700  chrY  56887744\n",
       "934655701  chrY  56887793\n",
       "934655702  chrY  56887802\n",
       "934655703  chrY  56887898\n",
       "\n",
       "[934655704 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty dataframe to store the concatenated data\n",
    "aou_variants_df = pd.DataFrame()\n",
    "\n",
    "# Check if the joined file already exists\n",
    "if not os.path.exists(aou_variants_file_path):\n",
    "    # Loop through chromosomes and append dataframes with tqdm\n",
    "    for filenum in tqdm(range(1, 9), desc='Processing Files'):\n",
    "        # Read the variants file into a pandas DataFrame\n",
    "        file_variants_df = pd.read_csv(\n",
    "            data_path + \"output_prefix_0\" + str(filenum) + \".tsv.gz\",\n",
    "            sep='-',\n",
    "            skiprows=1,\n",
    "            usecols=[0,1],\n",
    "            names=['chr', 'pos'],\n",
    "            dtype={'chr': str, 'pos': int},\n",
    "        )\n",
    "        \n",
    "        file_variants_df.drop_duplicates(inplace=True)\n",
    "\n",
    "        # Append the dataframe to the main dataframe\n",
    "        aou_variants_df = pd.concat([aou_variants_df, file_variants_df], ignore_index=True)\n",
    "    \n",
    "    # Add chr prefix for consistency\n",
    "    aou_variants_df['chr'] = 'chr' + aou_variants_df['chr'].astype(str)\n",
    "    \n",
    "    # Write aou_variants_df to a csv to avoid recomputing\n",
    "    aou_variants_df.to_csv(aou_variants_file_path, index=False, compression='gzip', sep='\\t')\n",
    "    \n",
    "else:\n",
    "    # Read the file into a pandas DataFrame\n",
    "    aou_variants_df = pd.read_csv(aou_variants_file_path, sep='\\t')\n",
    "\n",
    "aou_variants_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2bac06",
   "metadata": {},
   "source": [
    "## Train HMM on AoU chromosome 2 and get predictions for full genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45af0bd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define pattern for coverage file paths\n",
    "coverage_file_prefix = data_path + 'gnomad.genomes.r3.0.1.coverage_0.5_over10_chr'\n",
    "coverage_file_suffix = '.summary.tsv.gz'\n",
    "\n",
    "# Parameters for analysis\n",
    "order = 2\n",
    "\n",
    "# Initialize empty dataframes\n",
    "predictions_df = pd.DataFrame(columns=['chr', 'pos','prob_0', 'prob_1', 'observation'])\n",
    "\n",
    "# Define path to trained HMM\n",
    "hmm_file_path = results_path + 'HMM_aou_wgs_chr2_model.joblib'\n",
    "\n",
    "if os.path.exists(hmm_file_path):\n",
    "    # Load the pretrained model\n",
    "    model = joblib.load(hmm_file_path)\n",
    "    \n",
    "else:\n",
    "    # Filter rows for chromosome 2\n",
    "    chr_variants_df = aou_variants_df[aou_variants_df['chr'] == 'chr' + str(2)]\n",
    "    chr_coverage_df = pd.read_csv(coverage_file_prefix + str(2) + coverage_file_suffix, sep='\\t', names=['pos'])\n",
    "\n",
    "    # Get training data for the chromosome\n",
    "    observations, positions = get_sequence(chr_coverage_df, chr_variants_df)\n",
    "\n",
    "    # Fit HMM to Chromosome 2\n",
    "    model = fit_HMM(observations, order=order)\n",
    "\n",
    "    # Save the HMM model to a file to avoid retraining\n",
    "    joblib.dump(model, hmm_file_path)\n",
    "\n",
    "for chromnum in range(1,23):\n",
    "    print('-'*100)\n",
    "    print(\"PROCESSING CHROMOSOME\", str(chromnum))\n",
    "\n",
    "    # Filter rows for given chromosome\n",
    "    chr_variants_df = aou_variants_df[aou_variants_df['chr'] == 'chr' + str(chromnum)]\n",
    "    chr_coverage_df = pd.read_csv(coverage_file_prefix + str(chromnum) + coverage_file_suffix, sep='\\t', names=['pos'])\n",
    "    \n",
    "    # Get training data for the chromosome\n",
    "    observations, positions = get_sequence(chr_coverage_df, chr_variants_df)\n",
    "\n",
    "    # Fit HMM and retrieve probabilites\n",
    "    probabilities = get_HMM_predictions(observations, model, order=order)\n",
    "    \n",
    "    # Create a DataFrame with 'pos' reflecting the index of the original sequence and 'prob_0/1' as the predictions\n",
    "    chr_predictions_df = pd.DataFrame({'chr': 'chr' + str(chromnum),\n",
    "                                       'pos': positions[0:-order],\n",
    "                                       'prob_0': probabilities[:, 0], \n",
    "                                       'prob_1': probabilities[:, 1], \n",
    "                                       'observation': observations[0:-order]\n",
    "                                      })\n",
    "    \n",
    "    # Checkpoint chr_predictions_df to a csv to avoid memory bottleneck\n",
    "    chr_predictions_df.to_csv(results_path + \"HMM_aou_constraint_predictions_chr\" + str(chromnum) + \".tsv.gz\", index=False, compression='gzip', sep='\\t')\n",
    "    \n",
    "    # Plot histograms for predicted vs observed variants\n",
    "    plot_hist_from_predictions(chr_predictions_df)\n",
    "    \n",
    "    # Run regression\n",
    "    f_statistic, p_value_f_statistic = ols_regression(chr_predictions_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
