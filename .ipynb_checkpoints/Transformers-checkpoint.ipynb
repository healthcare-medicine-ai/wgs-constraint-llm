{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHieEcB26lal"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assuming this is your sequence\n",
    "sequence = sequence_str\n",
    "# Convert sequence to inputs and labels\n",
    "inputs = [[int(char) for char in sequence[:-1]]]\n",
    "labels = [int(char) for char in sequence[1:]]\n",
    "\n",
    "# Padding inputs to have the same length for each sequence\n",
    "max_seq_length = max(len(seq) for seq in inputs)\n",
    "inputs_padded = [seq + [0] * (max_seq_length - len(seq)) for seq in inputs]\n",
    "\n",
    "# Converting lists to tensors\n",
    "inputs_tensor = torch.tensor(inputs_padded, dtype=torch.float)\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)  # Output at each time step\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # Apply the linear layer to each time step\n",
    "        predictions = self.fc(lstm_out)\n",
    "        return predictions\n",
    "\n",
    "# Assuming inputs_tensor and labels_tensor have been correctly prepared\n",
    "# Adjust the shape of inputs_tensor to include a single feature per time step\n",
    "inputs_tensor = inputs_tensor.unsqueeze(-1)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = LSTMModel(input_dim, hidden_dim, output_dim)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Adjust labels_tensor to have the same sequence length as inputs for batch processing\n",
    "# Since your training example is simple and uses the whole sequence, ensure labels_tensor matches the expected dimensions:\n",
    "labels_tensor = labels_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.zero_grad()\n",
    "    outputs = model(inputs_tensor)\n",
    "    # Reshape outputs to [batch_size * seq_length, num_classes] and labels to [batch_size * seq_length]\n",
    "    outputs_reshaped = outputs.view(-1, output_dim)\n",
    "    labels_reshaped = labels_tensor.view(-1)\n",
    "    loss = loss_function(outputs_reshaped, labels_reshaped)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# The model is now trained on the provided sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yO9iBkL7Z7Sc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_sequence(sequence_length=100000000, window_size=20,\n",
    "                      prob_1_normal=0.9, prob_0_special=0.95,\n",
    "                      special_window_fraction=0.1):\n",
    "    # Calculate the number of windows\n",
    "    num_windows = sequence_length // window_size\n",
    "    # Determine how many windows will have the special probability\n",
    "    num_special_windows = int(num_windows * special_window_fraction)\n",
    "\n",
    "    # Generate random indices for the special windows\n",
    "    special_indices = np.random.choice(num_windows, num_special_windows, replace=False)\n",
    "\n",
    "    sequence = []\n",
    "    for i in range(num_windows):\n",
    "        if i in special_indices:\n",
    "            # Generate a window with special probabilities\n",
    "            window = np.random.choice([0, 1], size=window_size,\n",
    "                                      p=[prob_0_special, 1 - prob_0_special])\n",
    "        else:\n",
    "            # Generate a window with normal probabilities\n",
    "            window = np.random.choice([0, 1], size=window_size,\n",
    "                                      p=[1 - prob_1_normal, prob_1_normal])\n",
    "        sequence.extend(window)\n",
    "\n",
    "    # Handle the case where sequence_length is not a multiple of window_size\n",
    "    remaining_elements = sequence_length % window_size\n",
    "    if remaining_elements > 0:\n",
    "        sequence.extend(np.random.choice([0, 1], size=remaining_elements,\n",
    "                                         p=[1 - prob_1_normal, prob_1_normal]))\n",
    "\n",
    "    # Convert the sequence list to a string\n",
    "    sequence_str = ''.join(map(str, sequence))\n",
    "    return sequence_str\n",
    "\n",
    "# Generate the sequence\n",
    "sequence_str = generate_sequence()\n",
    "print(sequence_str[:1000])  # Display the first 1000 characters for brevity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hj1vZ4SlWEt-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Example new sequence\n",
    "new_sequence = sequence_str\n",
    "\n",
    "# Convert the new sequence to a tensor with the same format as the training data\n",
    "new_inputs = [[int(char) for char in new_sequence]]\n",
    "new_inputs_tensor = torch.tensor(new_inputs, dtype=torch.float).unsqueeze(-1)  # Add feature dimension\n",
    "\n",
    "# Assuming the model is already in evaluation mode with model.eval()\n",
    "# but let's set it explicitly just in case\n",
    "model.eval()\n",
    "\n",
    "# Make predictions with the model\n",
    "with torch.no_grad():\n",
    "    new_outputs = model(new_inputs_tensor)\n",
    "\n",
    "# Apply softmax to convert logits to probabilities\n",
    "probabilities = F.softmax(new_outputs, dim=2)  # Softmax over the num_classes dimension\n",
    "\n",
    "# The probabilities tensor has shape [batch_size, seq_length, num_classes]\n",
    "# For each position in the sequence, you get a probability distribution over the possible outputs (0 and 1)\n",
    "\n",
    "# Assuming you want to display these probabilities:\n",
    "for i, probs in enumerate(probabilities[0], start=1):  # Iterating over seq_length\n",
    "    print(f\"Position {i}, Probability of 0: {probs[0].item()}, Probability of 1: {probs[1].item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GICkS4ZG655G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4KCfWnW7F40"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_OGWh4qf7Qak",
    "outputId": "4e252a76-8b29-405a-d11f-7750c5026a3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([372, 40])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8oz1vnHg7RMF",
    "outputId": "2046561e-2eb9-4328-f277-7c6631622fe1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 768)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5xkelOz-Sza"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JsH40puVP4ur",
    "outputId": "312bfc2a-cb94-48c7-800e-90154684718e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.271479600807652e-06,\n",
       " 7.804544111422729e-06,\n",
       " 7.539450507465517e-06,\n",
       " 7.217479378596181e-06,\n",
       " 8.289206562039908e-06,\n",
       " 7.525671207986306e-06,\n",
       " 7.764267138554715e-06,\n",
       " 7.436168289132183e-06,\n",
       " 8.446281754004303e-06,\n",
       " 7.5189736890024506e-06,\n",
       " 8.118363439280074e-06,\n",
       " 8.267621524282731e-06,\n",
       " 7.834177267795894e-06,\n",
       " 8.08937238616636e-06,\n",
       " 7.939597708173096e-06,\n",
       " 7.478921361325774e-06,\n",
       " 8.273887942777947e-06,\n",
       " 7.480065505660605e-06,\n",
       " 8.944966793933418e-06,\n",
       " 9.715266969578806e-06,\n",
       " 9.209560630552005e-06,\n",
       " 9.217661499860696e-06,\n",
       " 9.301821592089254e-06,\n",
       " 9.702235729491804e-06]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0lrUyuVpE5-P",
    "outputId": "9446abab-8940-4e33-9856-3f4773f1d798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of '0' at index 1: 3.508684676489793e-05\n",
      "Probability of '1' at index 2: 1.4817873307038099e-05\n",
      "Probability of '0' at index 3: 7.0329442678485066e-06\n",
      "Probability of '1' at index 4: 1.5139834431465715e-05\n",
      "Probability of '0' at index 5: 7.1646395554125775e-06\n",
      "Probability of '1' at index 6: 1.279540538234869e-05\n",
      "Probability of '0' at index 7: 8.50523792905733e-06\n",
      "Probability of '1' at index 8: 2.1563757400144823e-05\n",
      "Probability of '0' at index 9: 9.990863873099443e-06\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DLYlDcSWDNwG",
    "outputId": "e65609b5-0746-45de-cce8-b096c379bdec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5AaGQv03DY_-",
    "outputId": "aa7df446-e44f-40ba-c6ce-15476333a011"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_sequence)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
